"""
EasyTTS / Genie-TTS Model Converter (GUI)

Goal:
  Convert GPT-SoVITS weights (.pth + .ckpt) into Genie-TTS ONNX model files,
  and generate an EasyTTS "model pack" folder structure compatible with ModelScope Studio.

Output structure (same as EasyTTS default packs):
  <output_root>/<model_name>/
    tts_models/                      # ONNX/.bin files generated by genie-tts
      vits_fp16.bin
      vits_fp32.onnx
      t2s_shared_fp16.bin
      t2s_first_stage_decoder_fp32.onnx
      t2s_encoder_fp32.bin
      t2s_encoder_fp32.onnx
      t2s_stage_decoder_fp32.onnx
      (optional v2ProPlus) prompt_encoder_fp16.bin / prompt_encoder_fp32.onnx
    prompt_wav/                      # reference audios (optional; you can fill later)
    prompt_wav.json                  # reference mapping (optional; empty template)
    easytts_pack.json                # metadata (model_name/language)
    _easytts_meta.json               # metadata (same content; accepted by EasyTTS)

Note:
  - Core conversion is done by the `genie-tts` Python package: `genie_tts.convert_to_onnx(...)`.
  - Run this script using the same Python environment as your MaiBot/EasyTTS, so deps match.
"""

from __future__ import annotations

import json
import os
import queue
import re
import threading
import time
import traceback
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import tkinter as tk
from tkinter import filedialog, messagebox, ttk


REQUIRED_V2_BASE = [
    "t2s_encoder_fp32.bin",
    "t2s_encoder_fp32.onnx",
    "t2s_first_stage_decoder_fp32.onnx",
    "t2s_shared_fp16.bin",
    "t2s_stage_decoder_fp32.onnx",
    "vits_fp16.bin",
    "vits_fp32.onnx",
]

OPTIONAL_V2PP = [
    "prompt_encoder_fp16.bin",
    "prompt_encoder_fp32.onnx",
]

def _find_local_genietts_repo() -> Optional[Path]:
    """
    Prefer a locally cloned Genie-TTS repo to avoid installing the full `genie-tts` package
    (which may pull native deps on Windows, e.g. jieba_fast).
    """
    env_repo = os.environ.get("GENIETTS_REPO", "").strip().strip('"')
    candidates: list[Path] = []
    if env_repo:
        candidates.append(Path(env_repo))

    # Common layout: <MaiBotOneKey>/tools/model_converter/easytts_model_converter_gui.py
    # with repo cloned at: <MaiBotOneKey>/tools/genietts/
    here = Path(__file__).resolve()
    candidates.append(here.parent.parent / "genietts")  # tools/genietts
    candidates.append((here.parent / ".." / "genietts"))  # model_converter/../genietts
    # Common layout in EasyTTS repo: <repo_root>/Genie-TTS-master/
    candidates.append(here.parent.parent.parent / "Genie-TTS-master")
    candidates.append(here.parent.parent.parent / "Genie-TTS")

    for c in candidates:
        try:
            c = c.resolve()
        except Exception:
            pass
        if (c / "src" / "genie_tts").is_dir():
            return c
    return None


def _convert_with_local_genietts_repo(
    *,
    repo: Path,
    torch_ckpt_path: str,
    torch_pth_path: str,
    output_dir: str,
) -> None:
    """
    Run conversion using Genie-TTS repo source code without importing `genie_tts/__init__.py`.
    This avoids heavy runtime dependencies (G2P / GenieData checks) that are irrelevant for conversion.
    """
    import importlib
    import importlib.machinery
    import sys
    import types

    repo_src = (repo / "src").resolve()
    pkg_root = (repo_src / "genie_tts").resolve()
    if not pkg_root.is_dir():
        raise RuntimeError(f"Invalid Genie-TTS repo: missing src/genie_tts: {repo}")

    # Create a minimal 'genie_tts' package in sys.modules WITHOUT executing its __init__.py.
    if "genie_tts" not in sys.modules:
        pkg = types.ModuleType("genie_tts")
        pkg.__path__ = [str(pkg_root)]
        pkg.__package__ = "genie_tts"
        pkg.__spec__ = importlib.machinery.ModuleSpec("genie_tts", loader=None, is_package=True)
        sys.modules["genie_tts"] = pkg
    else:
        pkg = sys.modules["genie_tts"]
        if getattr(pkg, "__path__", None) is None:
            pkg.__path__ = [str(pkg_root)]

    # Import converters (no __init__ side effects now).
    T2SModelConverter = importlib.import_module("genie_tts.Converter.v2.T2SConverter").T2SModelConverter
    VITSConverter = importlib.import_module("genie_tts.Converter.v2.VITSConverter").VITSConverter
    EncoderConverter = importlib.import_module("genie_tts.Converter.v2.EncoderConverter").EncoderConverter
    PromptEncoderConverter = importlib.import_module(
        "genie_tts.Converter.v2ProPlus.PromptEncoderConverter"
    ).PromptEncoderConverter

    # Resource files are stored in repo under src/genie_tts/Data/...
    v2_models = pkg_root / "Data" / "v2" / "Models"
    v2_keys = pkg_root / "Data" / "v2" / "Keys"
    v2pp_models = pkg_root / "Data" / "v2ProPlus" / "Models"
    v2pp_keys = pkg_root / "Data" / "v2ProPlus" / "Keys"

    encoder_onnx_path = v2_models / "t2s_encoder_fp32.onnx"
    stage_decoder_path = v2_models / "t2s_stage_decoder_fp32.onnx"
    first_stage_decoder_path = v2_models / "t2s_first_stage_decoder_fp32.onnx"
    t2s_keys_path = v2_keys / "t2s_onnx_keys.txt"

    # V2 vs V2ProPlus: follow upstream heuristic (pth > 150MB => v2ProPlus).
    is_v2pp = os.path.getsize(torch_pth_path) > 150 * 1024 * 1024

    cache_dir = os.path.join(output_dir, "_cache")
    os.makedirs(cache_dir, exist_ok=True)

    if is_v2pp:
        vits_onnx_path = v2pp_models / "vits_fp32.onnx"
        vits_keys_path = v2pp_keys / "vits_weights.txt"
        prompt_encoder_onnx_path = v2pp_models / "prompt_encoder_fp32.onnx"
        prompt_encoder_keys_path = v2pp_keys / "prompt_encoder_weights.txt"

        c1 = T2SModelConverter(
            torch_ckpt_path=torch_ckpt_path,
            stage_decoder_onnx_path=str(stage_decoder_path),
            first_stage_decoder_onnx_path=str(first_stage_decoder_path),
            key_list_file=str(t2s_keys_path),
            output_dir=output_dir,
            cache_dir=cache_dir,
        )
        c2 = VITSConverter(
            torch_pth_path=torch_pth_path,
            vits_onnx_path=str(vits_onnx_path),
            key_list_file=str(vits_keys_path),
            output_dir=output_dir,
            cache_dir=cache_dir,
        )
        c3 = EncoderConverter(
            ckpt_path=torch_ckpt_path,
            pth_path=torch_pth_path,
            onnx_input_path=str(encoder_onnx_path),
            output_dir=output_dir,
        )
        c4 = PromptEncoderConverter(
            torch_pth_path=torch_pth_path,
            prompt_encoder_onnx_path=str(prompt_encoder_onnx_path),
            key_list_file=str(prompt_encoder_keys_path),
            output_dir=output_dir,
            cache_dir=cache_dir,
        )
        c1.run_full_process()
        c2.run_full_process()
        c3.run_full_process()
        c4.run_full_process()
    else:
        vits_onnx_path = v2_models / "vits_fp32.onnx"
        vits_keys_path = v2_keys / "vits_onnx_keys.txt"

        c1 = T2SModelConverter(
            torch_ckpt_path=torch_ckpt_path,
            stage_decoder_onnx_path=str(stage_decoder_path),
            first_stage_decoder_onnx_path=str(first_stage_decoder_path),
            key_list_file=str(t2s_keys_path),
            output_dir=output_dir,
            cache_dir=cache_dir,
        )
        c2 = VITSConverter(
            torch_pth_path=torch_pth_path,
            vits_onnx_path=str(vits_onnx_path),
            key_list_file=str(vits_keys_path),
            output_dir=output_dir,
            cache_dir=cache_dir,
        )
        c3 = EncoderConverter(
            ckpt_path=torch_ckpt_path,
            pth_path=torch_pth_path,
            onnx_input_path=str(encoder_onnx_path),
            output_dir=output_dir,
        )
        c1.run_full_process()
        c2.run_full_process()
        c3.run_full_process()

    # Best-effort cleanup.
    try:
        import shutil

        shutil.rmtree(cache_dir, ignore_errors=True)
    except Exception:
        pass


def _safe_model_name(name: str) -> str:
    n = (name or "").strip()
    n = re.sub(r"[^A-Za-z0-9._-]+", "_", n)
    n = n.strip("._-")
    return n


@dataclass
class ConvertArgs:
    pth_path: str
    ckpt_path: str
    output_root: str
    model_name: str
    language: str
    overwrite_meta: bool


class App(tk.Tk):
    def __init__(self) -> None:
        super().__init__()
        self.title("EasyTTS 模型转换器（Genie-TTS / GUI）")
        self.geometry("920x620")
        self.minsize(900, 560)

        self._log_q: "queue.Queue[str]" = queue.Queue()
        self._worker: Optional[threading.Thread] = None

        self._pth_var = tk.StringVar()
        self._ckpt_var = tk.StringVar()
        self._out_root_var = tk.StringVar()
        self._name_var = tk.StringVar(value="sagiri")
        self._lang_var = tk.StringVar(value="jp")
        self._overwrite_meta_var = tk.BooleanVar(value=False)

        self._build_ui()
        self.after(80, self._drain_logs)

    def _build_ui(self) -> None:
        pad = {"padx": 10, "pady": 6}

        frm = ttk.Frame(self)
        frm.pack(fill="both", expand=True, **pad)

        row = 0
        ttk.Label(frm, text=".pth (SoVITS) 模型文件：").grid(row=row, column=0, sticky="w", **pad)
        ttk.Entry(frm, textvariable=self._pth_var).grid(row=row, column=1, sticky="ew", **pad)
        ttk.Button(frm, text="选择...", command=self._pick_pth).grid(row=row, column=2, sticky="ew", **pad)

        row += 1
        ttk.Label(frm, text=".ckpt (GPT) 权重文件：").grid(row=row, column=0, sticky="w", **pad)
        ttk.Entry(frm, textvariable=self._ckpt_var).grid(row=row, column=1, sticky="ew", **pad)
        ttk.Button(frm, text="选择...", command=self._pick_ckpt).grid(row=row, column=2, sticky="ew", **pad)

        row += 1
        ttk.Label(frm, text="输出根目录：").grid(row=row, column=0, sticky="w", **pad)
        ttk.Entry(frm, textvariable=self._out_root_var).grid(row=row, column=1, sticky="ew", **pad)
        ttk.Button(frm, text="选择...", command=self._pick_out_root).grid(row=row, column=2, sticky="ew", **pad)

        row += 1
        ttk.Label(frm, text="模型名（文件夹名）：").grid(row=row, column=0, sticky="w", **pad)
        ttk.Entry(frm, textvariable=self._name_var).grid(row=row, column=1, sticky="ew", **pad)

        name_hint = ttk.Label(frm, text="将生成：<输出根目录>/<模型名>/tts_models 等", foreground="#666666")
        name_hint.grid(row=row, column=2, sticky="w", **pad)

        row += 1
        ttk.Label(frm, text="language（写入 easytts_pack.json）：").grid(row=row, column=0, sticky="w", **pad)
        lang = ttk.Combobox(frm, textvariable=self._lang_var, values=["zh", "jp", "en", "hybrid"], state="readonly")
        lang.grid(row=row, column=1, sticky="w", **pad)
        ttk.Checkbutton(frm, text="覆盖写入 meta/prompt 文件", variable=self._overwrite_meta_var).grid(
            row=row, column=2, sticky="w", **pad
        )

        row += 1
        btnbar = ttk.Frame(frm)
        btnbar.grid(row=row, column=0, columnspan=3, sticky="ew", **pad)
        btnbar.columnconfigure(0, weight=1)

        self._run_btn = ttk.Button(btnbar, text="开始转换", command=self._on_run)
        self._run_btn.pack(side="left")
        self._validate_btn = ttk.Button(btnbar, text="校验输出目录", command=self._on_validate)
        self._validate_btn.pack(side="left", padx=(10, 0))
        ttk.Button(btnbar, text="清空日志", command=self._clear_log).pack(side="left", padx=(10, 0))

        row += 1
        tips = (
            "依赖：需要安装 genie-tts + torch（脚本本身不自动安装）。\n"
            "输出：会把 ONNX/.bin 写到 tts_models/，并生成 easytts_pack.json / _easytts_meta.json。\n"
            "提示：prompt_wav/ 与 prompt_wav.json 只是模板（可后续自行填参考音频与文本）。"
        )
        ttk.Label(frm, text=tips, justify="left").grid(row=row, column=0, columnspan=3, sticky="w", **pad)

        row += 1
        ttk.Label(frm, text="日志：").grid(row=row, column=0, sticky="w", **pad)

        row += 1
        self._log_text = tk.Text(frm, height=16, wrap="word")
        self._log_text.grid(row=row, column=0, columnspan=3, sticky="nsew", **pad)
        self._log_text.configure(state="disabled")

        scr = ttk.Scrollbar(frm, command=self._log_text.yview)
        scr.grid(row=row, column=3, sticky="ns", pady=6)
        self._log_text["yscrollcommand"] = scr.set

        frm.columnconfigure(1, weight=1)
        frm.rowconfigure(row, weight=1)

    def _pick_pth(self) -> None:
        path = filedialog.askopenfilename(
            title="选择 .pth 文件",
            filetypes=[("PyTorch .pth", "*.pth"), ("All files", "*.*")],
        )
        if path:
            self._pth_var.set(path)

    def _pick_ckpt(self) -> None:
        path = filedialog.askopenfilename(
            title="选择 .ckpt 文件",
            filetypes=[("Checkpoint .ckpt", "*.ckpt"), ("All files", "*.*")],
        )
        if path:
            self._ckpt_var.set(path)

    def _pick_out_root(self) -> None:
        path = filedialog.askdirectory(title="选择输出根目录（会生成 <root>/<model_name>/...）")
        if path:
            self._out_root_var.set(path)

    def _clear_log(self) -> None:
        self._log_text.configure(state="normal")
        self._log_text.delete("1.0", "end")
        self._log_text.configure(state="disabled")

    def _log(self, msg: str) -> None:
        ts = time.strftime("%H:%M:%S")
        self._log_q.put(f"[{ts}] {msg}")

    def _drain_logs(self) -> None:
        try:
            lines = []
            while True:
                lines.append(self._log_q.get_nowait())
        except queue.Empty:
            pass

        if lines:
            self._log_text.configure(state="normal")
            for line in lines:
                self._log_text.insert("end", line + "\n")
            self._log_text.see("end")
            self._log_text.configure(state="disabled")

        self.after(80, self._drain_logs)

    def _get_args(self) -> Optional[ConvertArgs]:
        pth = self._pth_var.get().strip().strip('"')
        ckpt = self._ckpt_var.get().strip().strip('"')
        out_root = self._out_root_var.get().strip().strip('"')
        model_name = _safe_model_name(self._name_var.get())
        language = (self._lang_var.get() or "").strip().lower()
        overwrite_meta = bool(self._overwrite_meta_var.get())

        if not pth or not Path(pth).is_file():
            messagebox.showerror("参数错误", "请选择有效的 .pth 文件。")
            return None
        if not ckpt or not Path(ckpt).is_file():
            messagebox.showerror("参数错误", "请选择有效的 .ckpt 文件。")
            return None
        if not out_root:
            messagebox.showerror("参数错误", "请选择输出根目录。")
            return None
        if not model_name:
            messagebox.showerror("参数错误", "请输入模型名（建议英文/数字/下划线）。")
            return None
        if language not in ("zh", "jp", "en", "hybrid"):
            messagebox.showerror("参数错误", "language 只能是 zh/jp/en/hybrid。")
            return None

        Path(out_root).mkdir(parents=True, exist_ok=True)

        return ConvertArgs(
            pth_path=pth,
            ckpt_path=ckpt,
            output_root=out_root,
            model_name=model_name,
            language=language,
            overwrite_meta=overwrite_meta,
        )

    def _on_validate(self) -> None:
        out_root = self._out_root_var.get().strip().strip('"')
        model_name = _safe_model_name(self._name_var.get())
        if not out_root or not model_name:
            messagebox.showerror("参数错误", "请先选择输出根目录并填写模型名。")
            return
        model_dir = Path(out_root) / model_name
        ok, report = validate_model_pack_dir(str(model_dir))
        self._log(report)
        if ok:
            messagebox.showinfo("校验通过", report)
        else:
            messagebox.showwarning("校验未通过", report)

    def _on_run(self) -> None:
        args = self._get_args()
        if not args:
            return
        if self._worker and self._worker.is_alive():
            messagebox.showwarning("正在运行", "当前已有转换任务在运行。")
            return

        self._run_btn.configure(state="disabled")
        self._validate_btn.configure(state="disabled")

        self._worker = threading.Thread(target=self._run_worker, args=(args,), daemon=True)
        self._worker.start()

    def _run_worker(self, args: ConvertArgs) -> None:
        try:
            self._log("开始转换（会生成 EasyTTS 模型包目录结构）...")
            self._log(f"pth:  {args.pth_path}")
            self._log(f"ckpt: {args.ckpt_path}")
            self._log(f"root: {args.output_root}")
            self._log(f"name: {args.model_name}")
            self._log(f"lang: {args.language}")

            local_repo = _find_local_genietts_repo()

            model_dir = Path(args.output_root) / args.model_name
            tts_models_dir = model_dir / "tts_models"
            prompt_wav_dir = model_dir / "prompt_wav"
            tts_models_dir.mkdir(parents=True, exist_ok=True)
            prompt_wav_dir.mkdir(parents=True, exist_ok=True)

            # Write meta files (optional overwrite)
            pack = {"model_name": args.model_name, "language": args.language}
            _write_json(model_dir / "easytts_pack.json", pack, overwrite=args.overwrite_meta, log=self._log)
            _write_json(model_dir / "_easytts_meta.json", pack, overwrite=args.overwrite_meta, log=self._log)

            # prompt_wav.json template (optional overwrite)
            _write_json(model_dir / "prompt_wav.json", {}, overwrite=args.overwrite_meta, log=self._log)

            # Convert -> tts_models/
            if local_repo:
                self._log(f"使用本地 Genie-TTS 仓库转换：{local_repo}")
                try:
                    _convert_with_local_genietts_repo(
                        repo=local_repo,
                        torch_pth_path=os.path.abspath(args.pth_path),
                        torch_ckpt_path=os.path.abspath(args.ckpt_path),
                        output_dir=os.path.abspath(str(tts_models_dir)),
                    )
                except Exception as e:
                    self._log("转换失败（本地 Genie-TTS 转换器抛异常）：")
                    self._log(str(e))
                    self._log(traceback.format_exc())
                    return
            else:
                self._log("未找到本地 Genie-TTS 仓库，尝试使用已安装的 genie-tts 包转换（Windows 不推荐）。")
                try:
                    import genie_tts as genie  # type: ignore

                    genie.convert_to_onnx(
                        torch_pth_path=os.path.abspath(args.pth_path),
                        torch_ckpt_path=os.path.abspath(args.ckpt_path),
                        output_dir=os.path.abspath(str(tts_models_dir)),
                    )
                except Exception as e:
                    self._log("转换失败：genie-tts 包不可用或依赖不完整。建议使用 run_with_maibot_python.bat（会自动使用本地仓库代码）。")
                    self._log(str(e))
                    self._log(traceback.format_exc())
                    return

            self._log("转换完成。开始校验输出...")
            ok, report = validate_model_pack_dir(str(model_dir))
            self._log(report)
            if ok:
                self._log("✅ 校验通过：模型包结构可用。")
            else:
                self._log("[WARN] 校验未通过：缺少文件。请确认输入的 .pth/.ckpt 是否匹配 V2/V2ProPlus。")
        finally:
            self.after(0, lambda: self._run_btn.configure(state="normal"))
            self.after(0, lambda: self._validate_btn.configure(state="normal"))


def _write_json(path: Path, obj: object, *, overwrite: bool, log) -> None:
    if path.exists() and not overwrite:
        log(f"跳过写入（已存在）：{path.name}")
        return
    try:
        path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")
        log(f"写入：{path.name}")
    except Exception as e:
        log(f"写入失败：{path.name}: {e}")


def validate_model_pack_dir(model_dir: str) -> tuple[bool, str]:
    p = Path(model_dir)
    if not p.exists():
        return False, f"模型目录不存在：{model_dir}"
    if not p.is_dir():
        return False, f"模型路径不是目录：{model_dir}"

    tts = p / "tts_models"
    if not tts.exists() or not tts.is_dir():
        return False, f"缺少 tts_models/：{tts}"

    missing_base = [f for f in REQUIRED_V2_BASE if not (tts / f).exists()]
    missing_v2pp = [f for f in OPTIONAL_V2PP if not (tts / f).exists()]

    lines = [f"模型目录：{p}", f"tts_models：{tts}"]
    if not missing_base:
        lines.append("Base 文件：[OK] 完整")
    else:
        lines.append("Base 文件：[MISSING] 缺失")
        lines.extend([f"  - {x}" for x in missing_base])

    if (p / "easytts_pack.json").exists() or (p / "_easytts_meta.json").exists():
        lines.append("Meta 文件：[OK] 已生成")
    else:
        lines.append("Meta 文件：[WARN] 未检测到（建议生成 easytts_pack.json / _easytts_meta.json）")

    if (p / "prompt_wav").exists():
        lines.append("prompt_wav/：[OK] 存在（可后续放参考音频）")
    else:
        lines.append("prompt_wav/：[WARN] 不存在")

    if (p / "prompt_wav.json").exists():
        lines.append("prompt_wav.json：[OK] 存在")
    else:
        lines.append("prompt_wav.json：[WARN] 不存在（可后续生成/填写）")

    # v2pp is optional, but show hint
    if not missing_v2pp:
        lines.append("v2ProPlus 附加文件：[OK] 检测到（看起来是 v2ProPlus）")
    else:
        lines.append("v2ProPlus 附加文件：未检测到（如果你的模型是 v2ProPlus，需要这两项）")
        lines.extend([f"  - {x}" for x in missing_v2pp])

    return (not missing_base), "\n".join(lines)


def main() -> None:
    app = App()
    try:
        app.tk.call("tk", "scaling", 1.15)
    except Exception:
        pass
    app.mainloop()


if __name__ == "__main__":
    main()
